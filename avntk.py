# -*- coding: utf-8 -*-
"""avntk.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sGgAFJxrbIIbX2q-JaOEUukhzdd8nfiZ
"""

import os,random
import tensorflow as tf
import cv2
import numpy as np

#drive.mount('/content/drive')

#config
data_path = os.path.join('D:','datasets_h5')
train_folder = os.path.join(data_path,'train_set')
test_folder = os.path.join(data_path,'test_set')
valid_folder = os.path.join(data_path,'valid_set')
epochs = 50
time =15
n_classes = 2
width,height,color_channels = 420,280,3
number_of_hiddenunits = 1
batch_size = 8

def batch_dispatch(data_folder):
    _data = os.listdir(data_folder)
    random.shuffle(_data)
    counter = 0
    it = int(batch_size/8)

    while counter<=len(_data):
        image_seqs=np.empty((0,time,height,width,color_channels))
        labels = np.empty((0,2))
        for i in range(it):
            np_data = np.load(os.path.join(data_folder,_data[counter]))
            image_seqs = np.vstack((image_seqs,np_data['name1']/255))
            labels = np.vstack((labels,np_data['name2']))
            '''np_data = np.load(os.path.join(data_folder,_data[counter]))
            image_seqs = np_data['name1']/255
            labels = np_data['name2']'''
            counter += 1
        yield image_seqs,labels

def get_valid_data(data_folder):
    _data = os.listdir(data_folder)
    random.shuffle(_data)
    image_seqs=np.empty((0,time,height,width,color_channels))
    labels = np.empty((0,2))
    for i in range(2):
      np_data = np.load(os.path.join(data_folder,_data[i]))
      image_seqs = np.vstack((image_seqs,np_data['name1']))
      labels = np.vstack((labels,np_data['name2']))
    return image_seqs/255,labels

def create_network():
    conv_model = tf.keras.models.Sequential()
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(16, (3,3), padding='same', activation='relu'),input_shape =(time,height,width,color_channels) ))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization()))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='SAME')))

    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu') ))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu') ))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization()))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='SAME')))   
    
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu') ))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu') ))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization()))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='SAME'))) 

    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu') ))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu') ))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization()))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='SAME')))

    '''conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu') ))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu') ))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization()))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='SAME')))'''

    #embedded
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(4096)))
    conv_model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(2048)))

    
    #image_features = model.embed_conv(conv_model)
    conv_model.add(tf.keras.layers.LSTM(number_of_hiddenunits, return_sequences=False))
    conv_model.add(tf.keras.layers.Dense(16))
    conv_model.add(tf.keras.layers.Dense(2))
    conv_model.add(tf.keras.layers.Activation('softmax'))
    conv_model.summary()
    return conv_model

def _trainer(network):
    network.compile(optimizer = 'adam', loss= 'binary_crossentropy',metrics = ['accuracy'])
    batch_generator = batch_dispatch(train_folder)
    val_batch = get_valid_data(valid_folder)
    network.fit_generator(batch_generator,epochs=epochs,steps_per_epoch=len(os.listdir(train_folder)) // batch_size,validation_data=val_batch,validation_steps=1)

network = create_network()
_trainer(network)